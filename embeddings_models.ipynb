{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hXma3j4fHWiI",
        "outputId": "327de27e-e66c-4f44-e568-af06ce27fc69"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.17.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.11)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.27.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2024.12.14)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets\n",
        "import os\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Training Embedding Model form Scratch***"
      ],
      "metadata": {
        "id": "65OERSF8SM4K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sentence_transformers import losses\n",
        "from sentence_transformers.evaluation import EmbeddingSimilarityEvaluator\n",
        "from sentence_transformers.training_args import SentenceTransformerTrainingArguments\n",
        "from sentence_transformers.trainer import SentenceTransformerTrainer"
      ],
      "metadata": {
        "id": "3kWUdQMpHvhU"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = load_dataset(\"glue\", \"mnli\", split=\"train\").select(range(50_000))\n",
        "train_dataset = train_dataset.remove_columns(\"idx\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dk2BDa8zHjv0",
        "outputId": "dce71bc5-37b3-4897-e86b-db5797edcde8"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset[2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sydDcVgxHxxj",
        "outputId": "82a21bb7-1442-4c1c-92ee-8fddeb62a7c9"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'premise': 'One of our number will carry out your instructions minutely.',\n",
              " 'hypothesis': 'A member of my team will execute your orders with immense precision.',\n",
              " 'label': 0}"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_model = SentenceTransformer('bert-base-uncased')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DfLwDPV1INuA",
        "outputId": "3801e954-d748-426e-a371-9a9fb0886a33"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:sentence_transformers.SentenceTransformer:No sentence-transformers model found with name bert-base-uncased. Creating a new one with mean pooling.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_loss = losses.SoftmaxLoss(model=embedding_model, sentence_embedding_dimension=embedding_model.get_sentence_embedding_dimension(),num_labels=3)"
      ],
      "metadata": {
        "id": "VPdpnxLIIOJd"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_sts = load_dataset(\"glue\",\"stsb\", split=\"validation\")\n",
        "evaluator = EmbeddingSimilarityEvaluator(\n",
        "sentences1=val_sts[\"sentence1\"],\n",
        "sentences2=val_sts[\"sentence2\"],\n",
        "scores=[score/5 for score in val_sts[\"label\"]], main_similarity=\"cosine\")"
      ],
      "metadata": {
        "id": "ZPJ51I-vIZ3n"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "args = SentenceTransformerTrainingArguments(output_dir=\"base_embedding_model\", num_train_epochs=1, per_device_train_batch_size=32,\n",
        "          per_device_eval_batch_size=32,\n",
        "          warmup_steps=100,\n",
        "          fp16=True,\n",
        "          eval_steps=100,\n",
        "          logging_steps=100,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "li2YzmozIprN",
        "outputId": "226c2941-98fa-4a2f-c62c-392f3d600c95"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = SentenceTransformerTrainer(\n",
        "      model=embedding_model,\n",
        "      args=args,\n",
        "      train_dataset=train_dataset,\n",
        "      loss=train_loss,\n",
        "      evaluator=evaluator\n",
        "    )\n",
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 149
        },
        "id": "ib3u7MASJBdf",
        "outputId": "b9313180-65a0-4ddd-e58a-400696f55fcc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
            "WARNING:sentence_transformers.data_collator:Column 'hypothesis' is at index 1, whereas a column with this name is usually expected at index 0. Note that the column order can be important for some losses, e.g. MultipleNegativesRankingLoss will always consider the first column as the anchor and the second as the positive, regardless of the dataset column names. Consider renaming the columns to match the expected order, e.g.:\n",
            "dataset = dataset.select_columns(['hypothesis', 'entailment', 'contradiction'])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='47' max='1563' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [  47/1563 29:33 < 16:35:44, 0.03 it/s, Epoch 0.03/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluator(embedding_model)"
      ],
      "metadata": {
        "id": "ur22DCb_JNeq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Cosine similarity loss function***"
      ],
      "metadata": {
        "id": "FL3QJJUlLujy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import Dataset, load_dataset"
      ],
      "metadata": {
        "id": "Dc5GDcmQL6Ya"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = load_dataset(\"glue\", \"mnli\", split=\"train\").select(range(50_000))\n",
        "train_dataset = train_dataset.remove_columns(\"idx\")"
      ],
      "metadata": {
        "id": "KLAcZPdgMBte"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mapping = {2: 0, 1: 0, 0:1}\n",
        "train_dataset = Dataset.from_dict({\n",
        "  \"sentence1\": train_dataset[\"premise\"],\n",
        "  \"sentence2\": train_dataset[\"hypothesis\"],\n",
        "  \"label\": [float(mapping[label]) for label in\n",
        "  train_dataset[\"label\"]]\n",
        "})"
      ],
      "metadata": {
        "id": "oiHFOj_GMHrW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_sts = load_dataset(\"glue\" ,\"stsb\", split=\"validation\")\n",
        "evaluator = EmbeddingSimilarityEvaluator( sentences1=val_sts[\"sentence1\"], sentences2=val_sts[\"sentence2\"],\n",
        "                                          scores=[score/5 for score in val_sts[\"label\"]], main_similarity=\"cosine\")"
      ],
      "metadata": {
        "id": "jLqphIU7MNYX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_model = SentenceTransformer(\"bert-base-uncased\")\n",
        "train_loss = losses.CosineSimilarityLoss(model=embedding_model)"
      ],
      "metadata": {
        "id": "69r2QKvnMe7z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "args = SentenceTransformerTrainingArguments(output_dir=\"cosineloss_embedding_model\",num_train_epochs=1,\n",
        "                                            per_device_train_batch_size=32,\n",
        "                                            per_device_eval_batch_size=32,\n",
        "                                            warmup_steps=100,\n",
        "                                            fp16=True,\n",
        "                                            eval_steps=100,\n",
        "                                            logging_steps=100,\n",
        "      )"
      ],
      "metadata": {
        "id": "bGpSY-joPU4R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = SentenceTransformerTrainer(model=embedding_model, args=args, train_dataset=train_dataset, loss=train_loss, evaluator=evaluator)"
      ],
      "metadata": {
        "id": "fhlhurx6Ppk2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "id": "Q-8wPi1kPw7_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluator(embedding_model)"
      ],
      "metadata": {
        "id": "GJsbG0z1Pyz7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Supervised fine tunning***"
      ],
      "metadata": {
        "id": "rc_v3xoBQOeF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "from sentence_transformers.evaluation import EmbeddingSimilarityEvaluator\n",
        "from sentence_transformers import losses, SentenceTransformer\n",
        "from sentence_transformers.trainer import SentenceTransformerTrainer\n",
        "from sentence_transformers.training_args import SentenceTransformerTrainingArguments"
      ],
      "metadata": {
        "id": "GZsd-qd4P13T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = load_dataset(\"glue\" ,\"mnli\", split=\"train\").select(range(50_000))\n",
        "train_dataset = train_dataset.remove_columns(\"idx\")"
      ],
      "metadata": {
        "id": "Gvzb6dekQhHn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_sts = load_dataset(\"glue\", \"stsb\", split=\"validation\")\n",
        "\n",
        "evaluator = EmbeddingSimilarityEvaluator(\n",
        "  sentences1=val_sts[\"sentence1\"],\n",
        "  sentences2=val_sts[\"sentence2\"],\n",
        "  scores=[score/5 for score in val_sts[\"label\"]],\n",
        "  main_similarity=\"cosine\"\n",
        ")"
      ],
      "metadata": {
        "id": "pqwcSmkhQl6W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')"
      ],
      "metadata": {
        "id": "AZ5jim26Q5PA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loss = losses.MultipleNegativesRankingLoss(model=embedding_model)"
      ],
      "metadata": {
        "id": "XKTSsNatQ8Xl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "args = SentenceTransformerTrainingArguments(output_dir=\"finetuned_embedding_model\",\n",
        "                                            num_train_epochs=1,\n",
        "                                            per_device_train_batch_size=32,\n",
        "                                            per_device_eval_batch_size=32,\n",
        "                                            warmup_steps=100,\n",
        "                                            fp16=True,\n",
        "                                            eval_steps=100,\n",
        "                                            logging_steps=100,\n",
        "                                          )"
      ],
      "metadata": {
        "id": "lpZwb1dDQ-8y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = SentenceTransformerTrainer(\n",
        "    model=embedding_model,\n",
        "    args=args,\n",
        "    train_dataset=train_dataset,\n",
        "    loss=train_loss,\n",
        "    evaluator=evaluator\n",
        ")"
      ],
      "metadata": {
        "id": "rf-SQZDXRLev"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "id": "o9uacZ1KRMxz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluator(embedding_model)"
      ],
      "metadata": {
        "id": "yX9zF-I0ROfs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}