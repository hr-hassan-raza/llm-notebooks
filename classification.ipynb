{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8506b35",
   "metadata": {},
   "source": [
    "### Classification\n",
    "The notebook includes experiments with classification models, comparing large language models (LLMs) to conventional methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b34cd3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from transformers.pipelines.pt_utils import KeyDataset\n",
    "from transformers import pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e9a790",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_dataset(\"rotten_tomatoes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ff2fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"cardiffnlp/twitter-roberta-base-sentiment-latest\"\n",
    "pipe = pipeline(\n",
    "    model = model_path,            \n",
    "    tokenizer = model_path,\n",
    "    return_all_scores = True,\n",
    "    device=\"cuda:0\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8fb9896",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = []\n",
    "for output in tqdm(pipe(KeyDataset(data['test'], 'text')), total=len(data['test'])):\n",
    "    negative_score = output[0][\"score\"]\n",
    "    positive_score = output[2][\"score\"]\n",
    "    assignment = np.argmax([negative_score, positive_score])\n",
    "    y_pred.append(assignment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a03adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_performance(y_true, y_pred):\n",
    "    performance = classification_report(y_true, y_pred, target_names=[\"Negative Review\", \"Positive Review\"])\n",
    "    print(performance)\n",
    "evaluate_performance(data[\"test\"][\"label\"], y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b601415c",
   "metadata": {},
   "source": [
    "#### Sentence Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ff8331",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer(\"sentence-transformers/all-mpnet-base-v2\")\n",
    "train_embeddings = model.encode(data['train']['text'], show_progress_bar=True)\n",
    "test_embeddings = model.encode(data['test']['text'], show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136bd29e",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(random_state=42)\n",
    "clf.fit(train_embeddings, data[\"train\"][\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f16ec14",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(test_embeddings)\n",
    "evaluate_performance(data[\"test\"][\"label\"], y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8f9e306",
   "metadata": {},
   "source": [
    "#### Google's Flan (LLM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf3107c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = pipeline(\n",
    "  \"text2text-generation\",\n",
    "  model=\"google/flan-t5-small\",\n",
    "  device=\"cuda:0\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80261726",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Is the following sentence positive or negative? \"\n",
    "data = data.map(lambda example: {\"t5\": prompt + example['text']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9efb16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = []\n",
    "for output in tqdm(pipe(KeyDataset(data[\"test\"], \"t5\")), total=len(data['test'])):\n",
    "    text = output[0][\"generated_text\"]\n",
    "    y_pred.append(0 if text == 'negative' else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ba7e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_performance(data[\"test\"][\"label\"], y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
